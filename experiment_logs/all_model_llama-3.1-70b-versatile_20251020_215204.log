2025-10-20 21:52:04,261 - INFO - Starting HR data extraction experiment with model: llama-3.1-70b-versatile
2025-10-20 21:52:04,265 - INFO - Loaded dataset with 100 entries
2025-10-20 21:52:04,266 - INFO - Processing message 1/100: Subject: Confirming New Hire - Danielle Johnson

Hey Danielle,

Just wanted to drop you a quick note...
2025-10-20 21:52:04,713 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:04,715 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:04,715 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:04,715 - ERROR - Raw response length: 0
2025-10-20 21:52:04,715 - ERROR - Raw response: ''...
2025-10-20 21:52:04,774 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:04,775 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:04,775 - WARNING - Masking failed for message 0, using original message
2025-10-20 21:52:04,830 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:04,831 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:04,887 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:04,887 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:04,887 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:04,887 - ERROR - Raw security response length: 0
2025-10-20 21:52:04,887 - ERROR - Raw security response: ''...
2025-10-20 21:52:05,059 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,060 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,060 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,060 - ERROR - Raw security response length: 0
2025-10-20 21:52:05,060 - ERROR - Raw security response: ''...
2025-10-20 21:52:05,061 - INFO - Processing message 2/100: Hey Joshua, 

Just wanted to give you a quick heads up that weâ€™re all set to bring on Joshua Walker ...
2025-10-20 21:52:05,117 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,118 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,118 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,118 - ERROR - Raw response length: 0
2025-10-20 21:52:05,119 - ERROR - Raw response: ''...
2025-10-20 21:52:05,188 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,189 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,190 - WARNING - Masking failed for message 1, using original message
2025-10-20 21:52:05,262 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,264 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,346 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,348 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,348 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,348 - ERROR - Raw security response length: 0
2025-10-20 21:52:05,348 - ERROR - Raw security response: ''...
2025-10-20 21:52:05,406 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,408 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,408 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,408 - ERROR - Raw security response length: 0
2025-10-20 21:52:05,408 - ERROR - Raw security response: ''...
2025-10-20 21:52:05,409 - INFO - Processing message 3/100: Hey Jill,

Iâ€™m excited to confirm that weâ€™re bringing on Jill Rhodes as our new Product Manager in t...
2025-10-20 21:52:05,471 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,472 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,472 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,472 - ERROR - Raw response length: 0
2025-10-20 21:52:05,472 - ERROR - Raw response: ''...
2025-10-20 21:52:05,530 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,531 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,532 - WARNING - Masking failed for message 2, using original message
2025-10-20 21:52:05,591 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,592 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,662 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,663 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,663 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,663 - ERROR - Raw security response length: 0
2025-10-20 21:52:05,663 - ERROR - Raw security response: ''...
2025-10-20 21:52:05,716 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,716 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,716 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,716 - ERROR - Raw security response length: 0
2025-10-20 21:52:05,716 - ERROR - Raw security response: ''...
2025-10-20 21:52:05,717 - INFO - Processing message 4/100: Hey Patricia, 

Just wanted to confirm that weâ€™ve got Patricia Miller on board as our new Junior Dat...
2025-10-20 21:52:05,775 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,775 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,776 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,776 - ERROR - Raw response length: 0
2025-10-20 21:52:05,776 - ERROR - Raw response: ''...
2025-10-20 21:52:05,844 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,846 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,846 - WARNING - Masking failed for message 3, using original message
2025-10-20 21:52:05,896 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,897 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,964 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:05,965 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:05,965 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:05,965 - ERROR - Raw security response length: 0
2025-10-20 21:52:05,965 - ERROR - Raw security response: ''...
2025-10-20 21:52:06,042 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,042 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,042 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,042 - ERROR - Raw security response length: 0
2025-10-20 21:52:06,042 - ERROR - Raw security response: ''...
2025-10-20 21:52:06,043 - INFO - Processing message 5/100: Hey Robert, 

Just wanted to confirm that weâ€™re bringing on Robert Johnson as our new Data Engineer ...
2025-10-20 21:52:06,096 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,096 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,096 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,096 - ERROR - Raw response length: 0
2025-10-20 21:52:06,096 - ERROR - Raw response: ''...
2025-10-20 21:52:06,148 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,148 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,148 - WARNING - Masking failed for message 4, using original message
2025-10-20 21:52:06,204 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,204 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,262 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,263 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,264 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,264 - ERROR - Raw security response length: 0
2025-10-20 21:52:06,264 - ERROR - Raw security response: ''...
2025-10-20 21:52:06,325 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,326 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,326 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,326 - ERROR - Raw security response length: 0
2025-10-20 21:52:06,326 - ERROR - Raw security response: ''...
2025-10-20 21:52:06,327 - INFO - Processing message 6/100: Hey team, 

Just wanted to confirm that weâ€™re bringing on Jeffery Wagner as our new Machine Learning...
2025-10-20 21:52:06,391 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,393 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,393 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,393 - ERROR - Raw response length: 0
2025-10-20 21:52:06,393 - ERROR - Raw response: ''...
2025-10-20 21:52:06,459 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,461 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,461 - WARNING - Masking failed for message 5, using original message
2025-10-20 21:52:06,521 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,523 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,591 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,593 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,593 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,593 - ERROR - Raw security response length: 0
2025-10-20 21:52:06,593 - ERROR - Raw security response: ''...
2025-10-20 21:52:06,660 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,661 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,661 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,661 - ERROR - Raw security response length: 0
2025-10-20 21:52:06,662 - ERROR - Raw security response: ''...
2025-10-20 21:52:06,662 - INFO - Processing message 7/100: Hey team! ðŸŽ‰ I'm super excited to confirm that weâ€™ve got Anthony Gonzalez joining us as our new UX Re...
2025-10-20 21:52:06,724 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,725 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,725 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,725 - ERROR - Raw response length: 0
2025-10-20 21:52:06,725 - ERROR - Raw response: ''...
2025-10-20 21:52:06,783 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,783 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,783 - WARNING - Masking failed for message 6, using original message
2025-10-20 21:52:06,838 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,839 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,899 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,899 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,899 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,899 - ERROR - Raw security response length: 0
2025-10-20 21:52:06,899 - ERROR - Raw security response: ''...
2025-10-20 21:52:06,971 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:06,972 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:06,972 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:06,972 - ERROR - Raw security response length: 0
2025-10-20 21:52:06,972 - ERROR - Raw security response: ''...
2025-10-20 21:52:06,972 - INFO - Processing message 8/100: Hey Debra, 

Just wanted to confirm that weâ€™re bringing on Debra Gardner as our new Junior Data Anal...
2025-10-20 21:52:07,027 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,028 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,028 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,028 - ERROR - Raw response length: 0
2025-10-20 21:52:07,028 - ERROR - Raw response: ''...
2025-10-20 21:52:07,117 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,118 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,119 - WARNING - Masking failed for message 7, using original message
2025-10-20 21:52:07,165 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,166 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,219 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,220 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,220 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,220 - ERROR - Raw security response length: 0
2025-10-20 21:52:07,220 - ERROR - Raw security response: ''...
2025-10-20 21:52:07,282 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,283 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,283 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,283 - ERROR - Raw security response length: 0
2025-10-20 21:52:07,283 - ERROR - Raw security response: ''...
2025-10-20 21:52:07,284 - INFO - Processing message 9/100: Hey team, 

Just wanted to confirm that weâ€™re bringing on Jeffrey Lawrence as our new Senior Softwar...
2025-10-20 21:52:07,333 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,334 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,334 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,334 - ERROR - Raw response length: 0
2025-10-20 21:52:07,335 - ERROR - Raw response: ''...
2025-10-20 21:52:07,394 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,396 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,396 - WARNING - Masking failed for message 8, using original message
2025-10-20 21:52:07,469 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,469 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,539 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,540 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,540 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,540 - ERROR - Raw security response length: 0
2025-10-20 21:52:07,540 - ERROR - Raw security response: ''...
2025-10-20 21:52:07,603 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,604 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,604 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,604 - ERROR - Raw security response length: 0
2025-10-20 21:52:07,604 - ERROR - Raw security response: ''...
2025-10-20 21:52:07,605 - INFO - Processing message 10/100: Hey Lisa, 

Just wanted to confirm that weâ€™re all set to bring on Lisa Smith as our new Machine Lear...
2025-10-20 21:52:07,669 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,670 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,670 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,670 - ERROR - Raw response length: 0
2025-10-20 21:52:07,670 - ERROR - Raw response: ''...
2025-10-20 21:52:07,728 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,728 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,729 - WARNING - Masking failed for message 9, using original message
2025-10-20 21:52:07,784 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,784 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,834 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,834 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,835 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,835 - ERROR - Raw security response length: 0
2025-10-20 21:52:07,835 - ERROR - Raw security response: ''...
2025-10-20 21:52:07,898 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,898 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,899 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,899 - ERROR - Raw security response length: 0
2025-10-20 21:52:07,899 - ERROR - Raw security response: ''...
2025-10-20 21:52:07,899 - INFO - Processing message 11/100: Hey Linda, 

Just wanted to confirm that weâ€™re all set to bring on Linda Wolfe as our new Finance An...
2025-10-20 21:52:07,964 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:07,964 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:07,964 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:07,965 - ERROR - Raw response length: 0
2025-10-20 21:52:07,965 - ERROR - Raw response: ''...
2025-10-20 21:52:08,040 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,040 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,040 - WARNING - Masking failed for message 10, using original message
2025-10-20 21:52:08,100 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,100 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,158 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,158 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,158 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,158 - ERROR - Raw security response length: 0
2025-10-20 21:52:08,158 - ERROR - Raw security response: ''...
2025-10-20 21:52:08,244 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,245 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,245 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,245 - ERROR - Raw security response length: 0
2025-10-20 21:52:08,245 - ERROR - Raw security response: ''...
2025-10-20 21:52:08,245 - INFO - Processing message 12/100: Hey team! ðŸŽ‰ I'm super excited to confirm that we've got Matthew Moore on board as our new Senior Sof...
2025-10-20 21:52:08,306 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,306 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,306 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,306 - ERROR - Raw response length: 0
2025-10-20 21:52:08,306 - ERROR - Raw response: ''...
2025-10-20 21:52:08,356 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,357 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,357 - WARNING - Masking failed for message 11, using original message
2025-10-20 21:52:08,416 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,416 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,470 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,470 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,470 - ERROR - Raw security response length: 0
2025-10-20 21:52:08,470 - ERROR - Raw security response: ''...
2025-10-20 21:52:08,528 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,528 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,529 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,529 - ERROR - Raw security response length: 0
2025-10-20 21:52:08,529 - ERROR - Raw security response: ''...
2025-10-20 21:52:08,529 - INFO - Processing message 13/100: Hey Susan, 

Just wanted to confirm that weâ€™re all set to bring on Susan Rogers as our new UX Resear...
2025-10-20 21:52:08,594 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,594 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,595 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,595 - ERROR - Raw response length: 0
2025-10-20 21:52:08,595 - ERROR - Raw response: ''...
2025-10-20 21:52:08,652 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,653 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,653 - WARNING - Masking failed for message 12, using original message
2025-10-20 21:52:08,708 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,709 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,766 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,767 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,767 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,767 - ERROR - Raw security response length: 0
2025-10-20 21:52:08,767 - ERROR - Raw security response: ''...
2025-10-20 21:52:08,827 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,827 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,827 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,827 - ERROR - Raw security response length: 0
2025-10-20 21:52:08,827 - ERROR - Raw security response: ''...
2025-10-20 21:52:08,828 - INFO - Processing message 14/100: Hey Christopher, 

Just wanted to confirm that weâ€™re bringing on Christopher Davis as our new Produc...
2025-10-20 21:52:08,916 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,917 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,917 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:08,917 - ERROR - Raw response length: 0
2025-10-20 21:52:08,917 - ERROR - Raw response: ''...
2025-10-20 21:52:08,968 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:08,969 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:08,969 - WARNING - Masking failed for message 13, using original message
2025-10-20 21:52:09,036 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:09,038 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:09,088 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:09,089 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:09,090 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:09,090 - ERROR - Raw security response length: 0
2025-10-20 21:52:09,090 - ERROR - Raw security response: ''...
2025-10-20 21:52:09,142 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:09,143 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:09,143 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:09,143 - ERROR - Raw security response length: 0
2025-10-20 21:52:09,143 - ERROR - Raw security response: ''...
2025-10-20 21:52:09,144 - INFO - Processing message 15/100: Subject: New Hire Confirmation

Hey Melanie,

Just wanted to confirm that weâ€™re bringing on board Me...
2025-10-20 21:52:09,196 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:09,198 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:09,198 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:09,198 - ERROR - Raw response length: 0
2025-10-20 21:52:09,198 - ERROR - Raw response: ''...
2025-10-20 21:52:09,272 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:09,274 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:09,274 - WARNING - Masking failed for message 14, using original message
2025-10-20 21:52:09,326 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:09,327 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:09,388 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:52:09,389 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:52:09,390 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:52:09,390 - ERROR - Raw security response length: 0
2025-10-20 21:52:09,390 - ERROR - Raw security response: ''...
