2025-10-20 21:35:35,396 - INFO - Starting HR data extraction experiment with model: llama-3.1-70b-versatile
2025-10-20 21:35:35,401 - INFO - Loaded dataset with 100 entries
2025-10-20 21:35:35,401 - INFO - Processing message 1/100: Subject: Confirming New Hire - Danielle Johnson

Hey Danielle,

Just wanted to drop you a quick note...
2025-10-20 21:35:35,573 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:35,574 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:35,574 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:35,574 - ERROR - Raw response length: 0
2025-10-20 21:35:35,574 - ERROR - Raw response: ''...
2025-10-20 21:35:35,669 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:35,670 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:35,670 - WARNING - Masking failed for message 0, using original message
2025-10-20 21:35:35,732 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:35,733 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:35,781 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:35,782 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:35,782 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:35,782 - ERROR - Raw security response length: 0
2025-10-20 21:35:35,782 - ERROR - Raw security response: ''...
2025-10-20 21:35:35,829 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:35,830 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:35,830 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:35,830 - ERROR - Raw security response length: 0
2025-10-20 21:35:35,830 - ERROR - Raw security response: ''...
2025-10-20 21:35:35,831 - INFO - Processing message 2/100: Hey Joshua, 

Just wanted to give you a quick heads up that we’re all set to bring on Joshua Walker ...
2025-10-20 21:35:35,887 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:35,889 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:35,889 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:35,889 - ERROR - Raw response length: 0
2025-10-20 21:35:35,889 - ERROR - Raw response: ''...
2025-10-20 21:35:35,941 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:35,942 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:35,942 - WARNING - Masking failed for message 1, using original message
2025-10-20 21:35:35,990 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:35,991 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,059 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,060 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,060 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,060 - ERROR - Raw security response length: 0
2025-10-20 21:35:36,060 - ERROR - Raw security response: ''...
2025-10-20 21:35:36,139 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,140 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,140 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,140 - ERROR - Raw security response length: 0
2025-10-20 21:35:36,140 - ERROR - Raw security response: ''...
2025-10-20 21:35:36,140 - INFO - Processing message 3/100: Hey Jill,

I’m excited to confirm that we’re bringing on Jill Rhodes as our new Product Manager in t...
2025-10-20 21:35:36,194 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,194 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,194 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,194 - ERROR - Raw response length: 0
2025-10-20 21:35:36,194 - ERROR - Raw response: ''...
2025-10-20 21:35:36,246 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,246 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,246 - WARNING - Masking failed for message 2, using original message
2025-10-20 21:35:36,308 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,309 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,387 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,388 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,388 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,389 - ERROR - Raw security response length: 0
2025-10-20 21:35:36,389 - ERROR - Raw security response: ''...
2025-10-20 21:35:36,465 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,466 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,466 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,466 - ERROR - Raw security response length: 0
2025-10-20 21:35:36,466 - ERROR - Raw security response: ''...
2025-10-20 21:35:36,467 - INFO - Processing message 4/100: Hey Patricia, 

Just wanted to confirm that we’ve got Patricia Miller on board as our new Junior Dat...
2025-10-20 21:35:36,528 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,529 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,529 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,529 - ERROR - Raw response length: 0
2025-10-20 21:35:36,529 - ERROR - Raw response: ''...
2025-10-20 21:35:36,580 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,580 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,580 - WARNING - Masking failed for message 3, using original message
2025-10-20 21:35:36,636 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,638 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,688 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,688 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,688 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,688 - ERROR - Raw security response length: 0
2025-10-20 21:35:36,688 - ERROR - Raw security response: ''...
2025-10-20 21:35:36,746 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,746 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,746 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,746 - ERROR - Raw security response length: 0
2025-10-20 21:35:36,747 - ERROR - Raw security response: ''...
2025-10-20 21:35:36,747 - INFO - Processing message 5/100: Hey Robert, 

Just wanted to confirm that we’re bringing on Robert Johnson as our new Data Engineer ...
2025-10-20 21:35:36,826 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,826 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,827 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:36,827 - ERROR - Raw response length: 0
2025-10-20 21:35:36,827 - ERROR - Raw response: ''...
2025-10-20 21:35:36,903 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,904 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:36,904 - WARNING - Masking failed for message 4, using original message
2025-10-20 21:35:36,961 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:36,961 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,010 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,011 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,011 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,011 - ERROR - Raw security response length: 0
2025-10-20 21:35:37,011 - ERROR - Raw security response: ''...
2025-10-20 21:35:37,054 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,054 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,054 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,054 - ERROR - Raw security response length: 0
2025-10-20 21:35:37,055 - ERROR - Raw security response: ''...
2025-10-20 21:35:37,055 - INFO - Processing message 6/100: Hey team, 

Just wanted to confirm that we’re bringing on Jeffery Wagner as our new Machine Learning...
2025-10-20 21:35:37,106 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,106 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,107 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,107 - ERROR - Raw response length: 0
2025-10-20 21:35:37,107 - ERROR - Raw response: ''...
2025-10-20 21:35:37,177 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,177 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,178 - WARNING - Masking failed for message 5, using original message
2025-10-20 21:35:37,237 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,238 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,299 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,300 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,300 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,301 - ERROR - Raw security response length: 0
2025-10-20 21:35:37,301 - ERROR - Raw security response: ''...
2025-10-20 21:35:37,386 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,387 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,387 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,387 - ERROR - Raw security response length: 0
2025-10-20 21:35:37,387 - ERROR - Raw security response: ''...
2025-10-20 21:35:37,388 - INFO - Processing message 7/100: Hey team! 🎉 I'm super excited to confirm that we’ve got Anthony Gonzalez joining us as our new UX Re...
2025-10-20 21:35:37,431 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,432 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,432 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,432 - ERROR - Raw response length: 0
2025-10-20 21:35:37,432 - ERROR - Raw response: ''...
2025-10-20 21:35:37,493 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,494 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,494 - WARNING - Masking failed for message 6, using original message
2025-10-20 21:35:37,569 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,570 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,635 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,636 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,636 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,636 - ERROR - Raw security response length: 0
2025-10-20 21:35:37,636 - ERROR - Raw security response: ''...
2025-10-20 21:35:37,695 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,696 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,696 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,696 - ERROR - Raw security response length: 0
2025-10-20 21:35:37,696 - ERROR - Raw security response: ''...
2025-10-20 21:35:37,697 - INFO - Processing message 8/100: Hey Debra, 

Just wanted to confirm that we’re bringing on Debra Gardner as our new Junior Data Anal...
2025-10-20 21:35:37,772 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,773 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,773 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,773 - ERROR - Raw response length: 0
2025-10-20 21:35:37,773 - ERROR - Raw response: ''...
2025-10-20 21:35:37,826 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,827 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,827 - WARNING - Masking failed for message 7, using original message
2025-10-20 21:35:37,926 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,927 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,985 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:37,986 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:37,986 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:37,986 - ERROR - Raw security response length: 0
2025-10-20 21:35:37,986 - ERROR - Raw security response: ''...
2025-10-20 21:35:38,031 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,032 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,032 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:38,032 - ERROR - Raw security response length: 0
2025-10-20 21:35:38,032 - ERROR - Raw security response: ''...
2025-10-20 21:35:38,032 - INFO - Processing message 9/100: Hey team, 

Just wanted to confirm that we’re bringing on Jeffrey Lawrence as our new Senior Softwar...
2025-10-20 21:35:38,095 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,096 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,096 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:38,096 - ERROR - Raw response length: 0
2025-10-20 21:35:38,096 - ERROR - Raw response: ''...
2025-10-20 21:35:38,155 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,156 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,156 - WARNING - Masking failed for message 8, using original message
2025-10-20 21:35:38,223 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,224 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,296 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,296 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,296 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:38,297 - ERROR - Raw security response length: 0
2025-10-20 21:35:38,297 - ERROR - Raw security response: ''...
2025-10-20 21:35:38,348 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,348 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,349 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:38,349 - ERROR - Raw security response length: 0
2025-10-20 21:35:38,349 - ERROR - Raw security response: ''...
2025-10-20 21:35:38,349 - INFO - Processing message 10/100: Hey Lisa, 

Just wanted to confirm that we’re all set to bring on Lisa Smith as our new Machine Lear...
2025-10-20 21:35:38,416 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,417 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,417 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:38,417 - ERROR - Raw response length: 0
2025-10-20 21:35:38,417 - ERROR - Raw response: ''...
2025-10-20 21:35:38,482 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,483 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,483 - WARNING - Masking failed for message 9, using original message
2025-10-20 21:35:38,534 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,534 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,584 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:35:38,584 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:35:38,585 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:35:38,585 - ERROR - Raw security response length: 0
2025-10-20 21:35:38,585 - ERROR - Raw security response: ''...
