2025-10-20 21:36:46,589 - INFO - Starting HR data extraction experiment with model: llama-3.1-70b-versatile
2025-10-20 21:36:46,594 - INFO - Loaded dataset with 100 entries
2025-10-20 21:36:46,594 - INFO - Processing message 1/100: Subject: Confirming New Hire - Danielle Johnson

Hey Danielle,

Just wanted to drop you a quick note...
2025-10-20 21:36:46,968 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:46,970 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:46,970 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:46,970 - ERROR - Raw response length: 0
2025-10-20 21:36:46,970 - ERROR - Raw response: ''...
2025-10-20 21:36:47,046 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,047 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,047 - WARNING - Masking failed for message 0, using original message
2025-10-20 21:36:47,109 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,109 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,158 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,159 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,159 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,159 - ERROR - Raw security response length: 0
2025-10-20 21:36:47,159 - ERROR - Raw security response: ''...
2025-10-20 21:36:47,223 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,224 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,224 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,224 - ERROR - Raw security response length: 0
2025-10-20 21:36:47,224 - ERROR - Raw security response: ''...
2025-10-20 21:36:47,225 - INFO - Processing message 2/100: Hey Joshua, 

Just wanted to give you a quick heads up that weâ€™re all set to bring on Joshua Walker ...
2025-10-20 21:36:47,287 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,287 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,287 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,287 - ERROR - Raw response length: 0
2025-10-20 21:36:47,287 - ERROR - Raw response: ''...
2025-10-20 21:36:47,353 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,354 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,354 - WARNING - Masking failed for message 1, using original message
2025-10-20 21:36:47,411 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,412 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,471 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,471 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,471 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,471 - ERROR - Raw security response length: 0
2025-10-20 21:36:47,471 - ERROR - Raw security response: ''...
2025-10-20 21:36:47,537 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,537 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,537 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,538 - ERROR - Raw security response length: 0
2025-10-20 21:36:47,538 - ERROR - Raw security response: ''...
2025-10-20 21:36:47,538 - INFO - Processing message 3/100: Hey Jill,

Iâ€™m excited to confirm that weâ€™re bringing on Jill Rhodes as our new Product Manager in t...
2025-10-20 21:36:47,597 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,597 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,597 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,597 - ERROR - Raw response length: 0
2025-10-20 21:36:47,597 - ERROR - Raw response: ''...
2025-10-20 21:36:47,659 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,660 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,660 - WARNING - Masking failed for message 2, using original message
2025-10-20 21:36:47,717 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,718 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,778 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,779 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,779 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,779 - ERROR - Raw security response length: 0
2025-10-20 21:36:47,779 - ERROR - Raw security response: ''...
2025-10-20 21:36:47,853 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,854 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,854 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,854 - ERROR - Raw security response length: 0
2025-10-20 21:36:47,854 - ERROR - Raw security response: ''...
2025-10-20 21:36:47,854 - INFO - Processing message 4/100: Hey Patricia, 

Just wanted to confirm that weâ€™ve got Patricia Miller on board as our new Junior Dat...
2025-10-20 21:36:47,909 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,910 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,910 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:47,910 - ERROR - Raw response length: 0
2025-10-20 21:36:47,910 - ERROR - Raw response: ''...
2025-10-20 21:36:47,967 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:47,968 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:47,968 - WARNING - Masking failed for message 3, using original message
2025-10-20 21:36:48,069 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,069 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,147 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,148 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,148 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:48,148 - ERROR - Raw security response length: 0
2025-10-20 21:36:48,148 - ERROR - Raw security response: ''...
2025-10-20 21:36:48,209 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,210 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,210 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:48,210 - ERROR - Raw security response length: 0
2025-10-20 21:36:48,210 - ERROR - Raw security response: ''...
2025-10-20 21:36:48,210 - INFO - Processing message 5/100: Hey Robert, 

Just wanted to confirm that weâ€™re bringing on Robert Johnson as our new Data Engineer ...
2025-10-20 21:36:48,271 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,271 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,271 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:48,271 - ERROR - Raw response length: 0
2025-10-20 21:36:48,271 - ERROR - Raw response: ''...
2025-10-20 21:36:48,336 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,336 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,336 - WARNING - Masking failed for message 4, using original message
2025-10-20 21:36:48,406 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,406 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,482 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,483 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,483 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:48,483 - ERROR - Raw security response length: 0
2025-10-20 21:36:48,483 - ERROR - Raw security response: ''...
2025-10-20 21:36:48,579 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,579 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,580 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:48,580 - ERROR - Raw security response length: 0
2025-10-20 21:36:48,580 - ERROR - Raw security response: ''...
2025-10-20 21:36:48,580 - INFO - Processing message 6/100: Hey team, 

Just wanted to confirm that weâ€™re bringing on Jeffery Wagner as our new Machine Learning...
2025-10-20 21:36:48,644 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,644 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,644 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:48,644 - ERROR - Raw response length: 0
2025-10-20 21:36:48,644 - ERROR - Raw response: ''...
2025-10-20 21:36:48,783 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,784 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,784 - WARNING - Masking failed for message 5, using original message
2025-10-20 21:36:48,845 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,845 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,916 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,917 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,917 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:48,917 - ERROR - Raw security response length: 0
2025-10-20 21:36:48,917 - ERROR - Raw security response: ''...
2025-10-20 21:36:48,983 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:48,983 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:48,983 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:48,983 - ERROR - Raw security response length: 0
2025-10-20 21:36:48,983 - ERROR - Raw security response: ''...
2025-10-20 21:36:48,984 - INFO - Processing message 7/100: Hey team! ðŸŽ‰ I'm super excited to confirm that weâ€™ve got Anthony Gonzalez joining us as our new UX Re...
2025-10-20 21:36:49,035 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,035 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,035 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,035 - ERROR - Raw response length: 0
2025-10-20 21:36:49,035 - ERROR - Raw response: ''...
2025-10-20 21:36:49,093 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,093 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,093 - WARNING - Masking failed for message 6, using original message
2025-10-20 21:36:49,155 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,155 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,213 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,214 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,214 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,214 - ERROR - Raw security response length: 0
2025-10-20 21:36:49,214 - ERROR - Raw security response: ''...
2025-10-20 21:36:49,269 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,269 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,269 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,269 - ERROR - Raw security response length: 0
2025-10-20 21:36:49,269 - ERROR - Raw security response: ''...
2025-10-20 21:36:49,270 - INFO - Processing message 8/100: Hey Debra, 

Just wanted to confirm that weâ€™re bringing on Debra Gardner as our new Junior Data Anal...
2025-10-20 21:36:49,328 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,329 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,329 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,329 - ERROR - Raw response length: 0
2025-10-20 21:36:49,329 - ERROR - Raw response: ''...
2025-10-20 21:36:49,383 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,383 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,383 - WARNING - Masking failed for message 7, using original message
2025-10-20 21:36:49,437 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,437 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,497 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,497 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,498 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,498 - ERROR - Raw security response length: 0
2025-10-20 21:36:49,498 - ERROR - Raw security response: ''...
2025-10-20 21:36:49,555 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,556 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,556 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,556 - ERROR - Raw security response length: 0
2025-10-20 21:36:49,556 - ERROR - Raw security response: ''...
2025-10-20 21:36:49,556 - INFO - Processing message 9/100: Hey team, 

Just wanted to confirm that weâ€™re bringing on Jeffrey Lawrence as our new Senior Softwar...
2025-10-20 21:36:49,613 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,614 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,614 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,614 - ERROR - Raw response length: 0
2025-10-20 21:36:49,614 - ERROR - Raw response: ''...
2025-10-20 21:36:49,673 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,674 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,674 - WARNING - Masking failed for message 8, using original message
2025-10-20 21:36:49,737 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,738 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,789 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,790 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,790 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,790 - ERROR - Raw security response length: 0
2025-10-20 21:36:49,790 - ERROR - Raw security response: ''...
2025-10-20 21:36:49,860 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,860 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,860 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,860 - ERROR - Raw security response length: 0
2025-10-20 21:36:49,860 - ERROR - Raw security response: ''...
2025-10-20 21:36:49,860 - INFO - Processing message 10/100: Hey Lisa, 

Just wanted to confirm that weâ€™re all set to bring on Lisa Smith as our new Machine Lear...
2025-10-20 21:36:49,921 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,922 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,922 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:49,922 - ERROR - Raw response length: 0
2025-10-20 21:36:49,922 - ERROR - Raw response: ''...
2025-10-20 21:36:49,977 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:49,978 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:49,978 - WARNING - Masking failed for message 9, using original message
2025-10-20 21:36:50,041 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,042 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,109 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,110 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,110 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:50,110 - ERROR - Raw security response length: 0
2025-10-20 21:36:50,110 - ERROR - Raw security response: ''...
2025-10-20 21:36:50,163 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,164 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,164 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:50,164 - ERROR - Raw security response length: 0
2025-10-20 21:36:50,164 - ERROR - Raw security response: ''...
2025-10-20 21:36:50,164 - INFO - Processing message 11/100: Hey Linda, 

Just wanted to confirm that weâ€™re all set to bring on Linda Wolfe as our new Finance An...
2025-10-20 21:36:50,218 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,218 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,218 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:50,218 - ERROR - Raw response length: 0
2025-10-20 21:36:50,218 - ERROR - Raw response: ''...
2025-10-20 21:36:50,265 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,266 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,266 - WARNING - Masking failed for message 10, using original message
2025-10-20 21:36:50,330 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,331 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,398 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,398 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,398 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:50,398 - ERROR - Raw security response length: 0
2025-10-20 21:36:50,398 - ERROR - Raw security response: ''...
2025-10-20 21:36:50,458 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,458 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,458 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:50,458 - ERROR - Raw security response length: 0
2025-10-20 21:36:50,458 - ERROR - Raw security response: ''...
2025-10-20 21:36:50,458 - INFO - Processing message 12/100: Hey team! ðŸŽ‰ I'm super excited to confirm that we've got Matthew Moore on board as our new Senior Sof...
2025-10-20 21:36:50,514 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,515 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,515 - ERROR - Failed to parse JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:50,515 - ERROR - Raw response length: 0
2025-10-20 21:36:50,515 - ERROR - Raw response: ''...
2025-10-20 21:36:50,576 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,577 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,577 - WARNING - Masking failed for message 11, using original message
2025-10-20 21:36:50,649 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,650 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,721 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,722 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,723 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:50,723 - ERROR - Raw security response length: 0
2025-10-20 21:36:50,723 - ERROR - Raw security response: ''...
2025-10-20 21:36:50,789 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-10-20 21:36:50,789 - ERROR - Error calling Groq API: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-20 21:36:50,790 - ERROR - Failed to parse security JSON response: Expecting value: line 1 column 1 (char 0)
2025-10-20 21:36:50,790 - ERROR - Raw security response length: 0
2025-10-20 21:36:50,790 - ERROR - Raw security response: ''...
2025-10-20 21:36:50,790 - INFO - Processing message 13/100: Hey Susan, 

Just wanted to confirm that weâ€™re all set to bring on Susan Rogers as our new UX Resear...
